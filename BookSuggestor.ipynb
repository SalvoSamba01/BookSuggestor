{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56604df7",
   "metadata": {},
   "source": [
    "# Progetto \"BookSuggestor\"\n",
    "\n",
    "**Nome**: Salvatore Alfio<br>\n",
    "**Cognome**: Sambataro<br>\n",
    "**Matricola**: 1000015834<br>\n",
    "**Corso**: Social Media Management<br>\n",
    "**Docente**: Antonino Furnari<br>\n",
    "**Anno accademico**: 2022/2023<br>\n",
    "\n",
    "\n",
    "# Introduzione\n",
    "\n",
    "Il progetto \"BookSuggestor\" consiste nella realizzazione di un sistema di raccomandazione che permette all'utente di ottenere consigli su libri da leggere, sulla base di un insieme di parole chiave fornite in input al sistema.\n",
    "Più nello specifico, il funzionamento del sistema è basato sull'utilizzo di un apposito dataset, che contiene diverse informazioni, ad esempio il titolo, la trama o l'autore, riguardo un'ampia varietà di libri.<br><br>\n",
    "Un altro obiettivo del progetto è quello di confrontare il funzionamento del sistema utilizzando due diverse tipologie di rappresentazione per il testo: \"**Bag of Words**\" e \"**Word Embeddings**\".<br><br>\n",
    "Infine, i risultati ottenuti dalle due varianti dell'algoritmo saranno analizzati e confrontati, usando la metrica di valutazione \"**Mean Reciprocal Rank**\", e saranno tratte le dovute conclusioni.\n",
    "\n",
    "# Dataset utilizzato\n",
    "\n",
    "Al fine di mettere a disposizione degli utenti un sistema di raccomandazione che tenga conto di un numero quanto più alto possibile di libri, si è deciso di utilizzare un dataset già pronto.<br>\n",
    "Nello specifico, il dataset utilizzato è il dataset open-spource \"[CMU Book Summmary](https://www.kaggle.com/datasets/ymaricar/cmu-book-summary-dataset)\" (fonte: [kaggle](https://www.kaggle.com/datasets)).\n",
    "<br>\n",
    "Più nello specifico, per ogni libro si hanno a disposizione:\n",
    "\n",
    "- Wikipedia ID \n",
    "- Freebase ID\n",
    "- Titolo\n",
    "- Autore\n",
    "- Data di pubblicazione\n",
    "- Generi\n",
    "- Riassunto della trama\n",
    "\n",
    "\n",
    "# Preprocessing dei dati\n",
    "\n",
    "Il sistema raccomanda all'utente un certo insieme di libri sulla base della somiglianza tra le parole chiave inserite dall'utente e il contenuto effettivo del libro, in termini di trama.\n",
    "\n",
    "Per il corretto funzionamento del sistema è necessario inizialmente effettuare una fase di preprocessing dei dati presenti all'interno del dataset.\n",
    "Nello specifico, le operazioni da svolgere sono:\n",
    "\n",
    "- caricare i record presenti nel file in un'apposita struttura dati\n",
    "- rimuovere eventuali record di libri per cui si hanno solo informazioni parziali (ad esempio, manca la trama, il titolo o l'autore)\n",
    "\n",
    "Tra le librerie utilizzate per tali operazioni abbiamo:\n",
    "\n",
    "- **pandas**: utile per la realizzazione di strutture dati apposite per la memorizzazione dei dati raccolti\n",
    "- **numpy**: fornisce la possibilità di usare diverse tipologie di funzioni matematiche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "272b77df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di libri disponibili:  12055\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "books = pd.read_csv(\"booksummaries.txt\", \n",
    "            header=None,sep=\"\\t\", \n",
    "            names=[\"Wikipedia ID\", \"Freebase ID\", \"Title\", \"Author\", \"Pub date\",\"Genres\",\"Summary\"])\n",
    "\n",
    "books = books.dropna(subset=['Title', 'Author', 'Summary','Genres'])\n",
    "books = books.reset_index(drop=True)\n",
    "\n",
    "print(\"Numero di libri disponibili: \", len(books))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2ff906",
   "metadata": {},
   "source": [
    "Una volta effettuato il preprocessing dei dati, le informazioni su ognuno dei libri presenti nel dataset sono memorizzate in un apposito dataframe, in cui ognuna delle righe ha la seguente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22ba948c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia ID</th>\n",
       "      <th>Freebase ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Pub date</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>620</td>\n",
       "      <td>/m/0hhy</td>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>1945-08-17</td>\n",
       "      <td>{\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...</td>\n",
       "      <td>Old Major, the old boar on the Manor Farm, ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wikipedia ID Freebase ID        Title         Author    Pub date  \\\n",
       "0           620     /m/0hhy  Animal Farm  George Orwell  1945-08-17   \n",
       "\n",
       "                                              Genres  \\\n",
       "0  {\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...   \n",
       "\n",
       "                                             Summary  \n",
       "0   Old Major, the old boar on the Manor Farm, ca...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0491417b",
   "metadata": {},
   "source": [
    "Come è possibile osservare dal record di esempio, è necessario effettuare un'ulteriore pulizia dei dati rigurdanti il genere dei libri.\n",
    "\n",
    "Notiamo che i generi sono memorizzati sotto forma di **coppie \"chiave-valore\"** : l'estrazione dei soli nomi dei generi può essere effettuata grazie all'utilizzo della libreria \"JSON\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c64ba29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/m/016lj8': 'Roman à clef', '/m/06nbt': 'Satire', '/m/0dwly': \"Children's literature\", '/m/014dfn': 'Speculative fiction', '/m/02xlf': 'Fiction'} \n",
      "\n",
      "['Roman à clef', 'Satire', \"Children's literature\", 'Speculative fiction', 'Fiction']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "dictionary = json.loads(books.iloc[0]['Genres'])\n",
    "print(dictionary,\"\\n\")\n",
    "\n",
    "genres = []\n",
    "for key in dictionary:\n",
    "    genres.append(dictionary[key])\n",
    "\n",
    "print(genres)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e809b0",
   "metadata": {},
   "source": [
    "Ripetiamo l'operazione appena vista per ognuno dei libri presenti nel dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69189824",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = []\n",
    "\n",
    "for genreList in books['Genres']:\n",
    "    dictionary = json.loads(genreList)\n",
    "    lista = []\n",
    "    for key in dictionary:\n",
    "        lista.append(dictionary[key])\n",
    "    genres.append(\",\".join(lista))\n",
    "\n",
    "books['Genres'] = genres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f3f5bb",
   "metadata": {},
   "source": [
    "Adesso ognuno dei record avrà nel campo \"Genres\" solo i nomi dei generi di appartenenza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8d509ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Roman à clef,Satire,Children's literature,Speculative fiction,Fiction\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.iloc[0][\"Genres\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083a5c49",
   "metadata": {},
   "source": [
    "# Algoritmi utilizzati\n",
    "\n",
    "Per poter implementare la ricerca di un libro sulla base di specifiche parole chiave, è necessario utilizzare un'apposita funzione di rappresentazione per il testo.<br>\n",
    "Le rappresentazioni che saranno utilizzate per questo progetto sono due:\n",
    "\n",
    "- **Bag of Words**\n",
    "- **Word Embeddings**\n",
    "\n",
    "## Rappresentazione Bag of Words\n",
    "\n",
    "La rappresentazione \"**Bag of Words**\" è una rappresentazione che permette di rappresentare un testo sulla base dell'insieme delle parole che sono in esso contenute. Lo svantaggio principale è che essa tiene conto esclusivamente del numero di occorrenze di ogni parola all'interno del testo in questione, mentre non si considera il significato e il contesto della singola parola.\n",
    "\n",
    "### Calcolo della rappresentazione Bag of Words tramite la libreria \" scikit-learn\"\n",
    "\n",
    "Per calcolare il vettore Bag of Words di un testo, si è scelto di fare uso della libreria \"**scikit-learn**\", la quale mette a disposizione un apposito modulo chiamato \"**CountVectorizer**\" che permette di calcolare la rappresentazione Bag of Words sulla base di un insieme di testi, detto \"**corpus di documenti**\".\n",
    "\n",
    "La prima cosa da fare è importare il modulo \"CountVectorizer\" e creare un oggetto di tipo \"CountVectorizer\" con l'apposita funzione:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b4c64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f54b1fa",
   "metadata": {},
   "source": [
    "### Definizione del \"vocabolario dei termini\"\n",
    "\n",
    "A questo punto, bisogna definire il corpus di documenti rispetto al quale calcolare la rappresentazione. In questo caso, i documenti saranno le trame dei singoli libri.<br>\n",
    "Successivamente, attraverso la funzione \"*count_vect.fit(...)*\" potremo creare il cosiddetto \"**vocabolario dei termini**\", cioè l'insieme di tutte le diverse parole presenti nei documenti del corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13628b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = books[\"Summary\"].tolist()\n",
    "_ = count_vect.fit(summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11abd4f3",
   "metadata": {},
   "source": [
    "Visualizziamo il numero di termini del vocabolario e una parte di esso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2d13430",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensione del vocabolario:  103311 \n",
      "\n",
      "[('old', 64934), ('major', 55659), ('the', 90890), ('boar', 11527), ('on', 65121), ('manor', 56222), ('farm', 32178), ('calls', 14579), ('animals', 4890), ('for', 34266)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensione del vocabolario: \", len(count_vect.vocabulary_),\"\\n\")\n",
    "\n",
    "print(list(count_vect.vocabulary_.items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4ff558",
   "metadata": {},
   "source": [
    "Come possiamo notare, il vocabolario è un dizionario in cui le \"chiavi\" sono le diverse parole trovate, mentre il \"valore\" associato ad ognuno di essi è l'\"ID\" associato alcorrispondente termine.\n",
    "\n",
    "### Calcolo della rappresentazione di singoli testi\n",
    "\n",
    "Una volta definito il vocabolario, possiamo calcolare il vettore Bag of Words dei riassunti delle trame dei diversi libri del dataset attraverso l'apposita funzione \"*count_vect.transform(...)*\", la quale dovrà essere chiamata passando come input le trame dei diversi libri.<br>\n",
    "Usiamo inoltre la libreria \"**tqdm**\" per creare una \"barra di caricamento\" per seguire l'andamento del calcolo delle diverse rappresentazioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3b971ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 12055/12055 [00:08<00:00, 1458.44it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "BOWSummaries = []\n",
    "\n",
    "for i in tqdm(range(len(summaries))):\n",
    "    BOWSummaries.append(np.array(count_vect.transform([str(summaries[i])]).todense()).flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4584892c",
   "metadata": {},
   "source": [
    "Consideriamo il primo libro del dataset, e stampiamo il corrispondente vettore Bag of Words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a708635c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAMA:\n",
      "\n",
      "   Old Major, the old boar on the Manor Farm, calls the animals on the farm for a meeting, where he compares the humans to parasites and teaches the animals a revolutionary song, 'Beasts of England'. When Major dies, two young pigs, Snowball and Napoleon, assume command and turn his dream into a philosophy. The animals revolt and drive the drunken and irresponsible Mr Jones from the farm, renaming it \"Animal Farm\". They adopt Seven Commandments of Animal-ism, the most important of which is, \"All animals are equal\". Snowball attempts to teach the animals reading and writing; food is plentiful, and the farm runs smoothly. The pigs elevate themselves to positions of leadership and set aside special food items, ostensibly for their personal health. Napoleon takes the pups from the farm dogs and trains them privately. Napoleon and Snowball struggle for leadership. When Snowball announces his plans to build a windmill, Napoleon has his dogs chase Snowball away and declares himself leader. Napoleon enacts changes to the governance structure of the farm, replacing meetings with a committee of pigs, who will run the farm. Using a young pig named Squealer as a \"mouthpiece\", Napoleon claims credit for the windmill idea. The animals work harder with the promise of easier lives with the windmill. After a violent storm, the animals find the windmill annihilated. Napoleon and Squealer convince the animals that Snowball destroyed it, although the scorn of the neighbouring farmers suggests that its walls were too thin. Once Snowball becomes a scapegoat, Napoleon begins purging the farm with his dogs, killing animals he accuses of consorting with his old rival. He and the pigs abuse their power, imposing more control while reserving privileges for themselves and rewriting history, villainising Snowball and glorifying Napoleon. Squealer justifies every statement Napoleon makes, even the pigs' alteration of the Seven Commandments of Animalism to benefit themselves. 'Beasts of England' is replaced by an anthem glorifying Napoleon, who appears to be adopting the lifestyle of a man. The animals remain convinced that they are better off than they were when under Mr Jones. Squealer abuses the animals' poor memories and invents numbers to show their improvement. Mr Frederick, one of the neighbouring farmers, attacks the farm, using blasting powder to blow up the restored windmill. Though the animals win the battle, they do so at great cost, as many, including Boxer the workhorse, are wounded. Despite his injuries, Boxer continues working harder and harder, until he collapses while working on the windmill. Napoleon sends for a van to take Boxer to the veterinary surgeon's, explaining that better care can be given there. Benjamin, the cynical donkey, who \"could read as well as any pig\", notices that the van belongs to a knacker, and attempts to mount a rescue; but the animals' attempts are futile. Squealer reports that the van was purchased by the hospital and the writing from the previous owner had not been repainted. He recounts a tale of Boxer's death in the hands of the best medical care. Years pass, and the pigs learn to walk upright, carry whips and wear clothes. The Seven Commandments are reduced to a single phrase: \"All animals are equal, but some animals are more equal than others\". Napoleon holds a dinner party for the pigs and the humans of the area, who congratulate Napoleon on having the hardest-working but least fed animals in the country. Napoleon announces an alliance with the humans, against the labouring classes of both \"worlds\". He abolishes practices and traditions related to the Revolution, and changes the name of the farm to \"The Manor Farm\". The animals, overhearing the conversation, notice that the faces of the pigs have begun changing. During a poker match, an argument breaks out between Napoleon and Mr Pilkington, and the animals realise that the faces of the pigs look like the faces of humans, and no one can tell the difference between them. The pigs Snowball, Napoleon, and Squealer adapt Old Major's ideas into an actual philosophy, which they formally name Animalism. Soon after, Napoleon and Squealer indulge in the vices of humans (drinking alcohol, sleeping in beds, trading). Squealer is employed to alter the Seven Commandments to account for this humanisation, an allusion to the Soviet government's revising of history in order to exercise control of the people's beliefs about themselves and their society. The original commandments are: # Whatever goes upon two legs is an enemy. # Whatever goes upon four legs, or has wings, is a friend. # No animal shall wear clothes. # No animal shall sleep in a bed. # No animal shall drink alcohol. # No animal shall kill any other animal. # All animals are equal. Later, Napoleon and his pigs secretly revise some commandments to clear them of accusations of law-breaking (such as \"No animal shall drink alcohol\" having \"to excess\" appended to it and \"No animal shall sleep in a bed\" with \"with sheets\" added to it). The changed commandments are as follows, with the changes bolded: * 4 No animal shall sleep in a bed with sheets. * 5 No animal shall drink alcohol to excess. * 6 No animal shall kill any other animal without cause. Eventually these are replaced with the maxims, \"All animals are equal, but some animals are more equal than others\", and \"Four legs good, two legs better!\" as the pigs become more human. This is an ironic twist to the original purpose of the Seven Commandments, which were supposed to keep order within Animal Farm by uniting the animals together against the humans, and prevent animals from following the humans' evil habits. Through the revision of the commandments, Orwell demonstrates how simply political dogma can be turned into malleable propaganda. \n",
      "\n",
      "\n",
      "#########################################################\n",
      "\n",
      "\n",
      "Dimensione del vettore Bag of Words:  103311 \n",
      "\n",
      "\n",
      "#########################################################\n",
      "\n",
      "\n",
      "Vettore BOW:\n",
      "\n",
      " [0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAMA:\\n\\n \",summaries[0], \"\\n\\n\\n#########################################################\\n\\n\")\n",
    "print(\"Dimensione del vettore Bag of Words: \", len(BOWSummaries[0]) , \"\\n\\n\\n#########################################################\\n\\n\")\n",
    "print(\"Vettore BOW:\\n\\n\" , BOWSummaries[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6905472a",
   "metadata": {},
   "source": [
    "Notiamo che:\n",
    "\n",
    "- la dimensione della rappresentazione è pari alla dimensione del vocabolario\n",
    "- poichè il vocabolario è molto ampio, la maggior parte delle componenti del vettore avranno valore pari a 0\n",
    "\n",
    "\n",
    "### Calcolo della similarità tra parole chiave e trame\n",
    "\n",
    "Dopo aver calcolato i vettori Bag of Words delle trame dei libri, dobbiamo adesso calcolare la rappresentazione delle keyword inserite in input dall'utente.\n",
    "\n",
    "Supponendo che le keyword siano memorizzate in un'apposita variabile, calcoliamo la relativa rappresentazione BOW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "775fd2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = \"story of a group of farm animals who rebel against their human farmer, hoping to create a society where the animals can be equal, free, and happy. Ultimately, the rebellion is betrayed, and under the dictatorship of a pig named Napoleon, the farm ends up in a state as bad as it was before\"\n",
    "\n",
    "BOWkeywords = np.array(count_vect.transform([keywords]).todense()).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d94d522",
   "metadata": {},
   "source": [
    "A questo punto, per cercare libri le cui trame sono simili alle keyword inserite in input, una soluzione possibile è calcolare una **misura di distanza** tra la rappresentazione delle keyword e le rappresentazioni dei singoli testi.<br><br>\n",
    "In questo caso, la misura di distanza implementata è la **similarità del coseno**, definita come:<br><br>\n",
    "$$cossim(x,y)=\\frac{x\\cdot y} {\\left \\| x \\right \\| \\cdot \\left \\| y \\right \\| }$$ <br>\n",
    "Il calcolo della similarità può essere effettuato attraverso due apposite funzioni della libreria \"NumPy\":\n",
    "\n",
    "- ***dot()***: calcolo del prodotto scalare tra due vettori\n",
    "- ***norm()***: calcolo della norma di un vettore\n",
    "\n",
    "Calcoliamo quindi le diverse similarità tra le keyword e i libri come segue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59160e67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 12055/12055 [00:06<00:00, 1722.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Animal Farm', 'George Orwell', 0.6654636523305504),\n",
       " ('A Clockwork Orange', 'Anthony Burgess', 0.5723264722039985),\n",
       " ('The Plague', 'Albert Camus', 0.5963706247825356),\n",
       " ('A Fire Upon the Deep', 'Vernor Vinge', 0.619436717447886),\n",
       " ('All Quiet on the Western Front',\n",
       "  'Erich Maria Remarque',\n",
       "  0.5752185890586847),\n",
       " ('A Wizard of Earthsea', 'Ursula K. Le Guin', 0.5632036628427579),\n",
       " ('Blade Runner 3: Replicant Night', 'K. W. Jeter', 0.47267155030848435),\n",
       " ('Blade Runner 2: The Edge of Human', 'K. W. Jeter', 0.4539543919769876),\n",
       " ('Crash', 'J. G. Ballard', 0.47943886564996496),\n",
       " ('Children of Dune', 'Frank Herbert', 0.5473379265047649)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "similarities = list()\n",
    "\n",
    "for i in tqdm(range(len(BOWSummaries))):\n",
    "    title = books.iloc[i][\"Title\"]\n",
    "    author = books.iloc[i][\"Author\"]\n",
    "    similarities.append( tuple ((title , author , (dot(BOWSummaries[i], BOWkeywords))/(norm(BOWSummaries[i])*norm(BOWkeywords)))))\n",
    "\n",
    "similarities[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9417b41c",
   "metadata": {},
   "source": [
    "Per concludere, ordiniamo i diversi libri sulla base del coefficente di similarità calcolato, e restituiamo all'utente i libri più simili in base alle keywords inserite.<br>\n",
    "A titolo di esempio, restituiamo i primi 3 libri con il coefficente di similarità più alto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82b737b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libri più simili alle parole chiave date in input:\n",
      "\n",
      "1 ) \" Animal Farm \" ,  George Orwell  (Coeff.Similarità:  0.6654636523305504 )\n",
      "2 ) \" Snowball's Chance \" ,  John Reed  (Coeff.Similarità:  0.6647950024205023 )\n",
      "3 ) \" The Alteration \" ,  Kingsley Amis  (Coeff.Similarità:  0.6534984264417577 )\n"
     ]
    }
   ],
   "source": [
    "similarities = sorted(similarities, key = lambda x: x[2] , reverse = True)\n",
    "\n",
    "print(\"Libri più simili alle parole chiave date in input:\\n\")\n",
    "for i in range(3):\n",
    "    print(i+1,') \"',similarities[i][0] , '\" , ', similarities[i][1] ,' (Coeff.Similarità: ',similarities[i][2], \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b839e339",
   "metadata": {},
   "source": [
    "Possiamo anche notare che i risultati \"meno simili\" all'input sono dei libri totalmente diversi da quello che l'utente ha richiesto: essi infatti molto probabilmente avranno dei coefficenti di similarità prossimi o uguali a 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5951a6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libri meno simili alle parole chiave date in input:\n",
      "\n",
      "1 ) \" The Kennel Murder Case \" ,  S. S. Van Dine  (Coeff.Similarità:  0.0 )\n",
      "2 ) \" Slavers \" ,  Chris Pramas  (Coeff.Similarità:  0.0 )\n",
      "3 ) \" Deathstalker \" ,  Simon Green  (Coeff.Similarità:  0.0 )\n"
     ]
    }
   ],
   "source": [
    "similarities = sorted(similarities, key = lambda x: x[2] , reverse = False)\n",
    "\n",
    "print(\"Libri meno simili alle parole chiave date in input:\\n\")\n",
    "for i in range(3):\n",
    "    print(i+1,') \"',similarities[i][0] , '\" , ', similarities[i][1] ,' (Coeff.Similarità: ',similarities[i][2], \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dcd687",
   "metadata": {},
   "source": [
    "## Approccio alternativo: rappresentazione \"Word Embeddings\"\n",
    "\n",
    "Oltre a rappresentare un testo con la rappresentazione \"Bag of Words\", possiamo usare un'altra tipologia di rappresentazione, chiamata \"**Word Embeddings**\".<br>\n",
    "Nello specifico, la rappresentazione Word Embeddings è una rappresentazione che tiene conto della semantica e del contesto delle singole parole, in maniera tale che **parole usate in maniera simile abbiano una rappresentazione simile**.\n",
    "\n",
    "Data una serie di testi, in Python è possibile calcolare la rappresentazione Word Embeddings in diversi modi: in questo caso, si farà uso della libreria \"SpaCy\".\n",
    "\n",
    "La prima cosa da fare è caricate uno dei modelli offerti dalla libreria: in questo caso, si è scelto di usare il modello \"***en_core_web_md***\".<br>\n",
    "Esso può essere caricato in Python con le seguenti istruzioni:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f346a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c6ed26",
   "metadata": {},
   "source": [
    "A questo punto, per calcolare i Word Embedding delle trame dei diversi libri del dataset, si dovranno svolgere le seguenti operazioni:\n",
    "\n",
    "- **Pre-processing sulle trame dei libri**: applicazione di una pipeline di NLP che prevede operazioni di tokenizzazione, rimozione delle Stop Words e della punteggiatura, e lemmatizzazione del testo, attraverso le apposite funzioni messe a disposizione dalla libreria \"SpaCy\"\n",
    "- **Calcolo del vettore Word Embedding delle singole parole di un documento**\n",
    "- **Calcolo del vettore Word Embedding di un intero documento**: ciò può essere fatto calcolando la media degli embedding delle parole presenti nel documento in questione\n",
    "\n",
    "***N.B.*** *A differenza dell'algoritmo basato sulla rappresentazione Bag of Words, in questo caso consideriamo solo un ristretto sotto-insieme del dataset, in quanto in caso contrario il calcolo degli embedding richiederebbe troppo tempo.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b43e8d57",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# consideriamo solo i primi 200 libri\n",
    "\n",
    "booksSample = books.head(n=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b8027d",
   "metadata": {},
   "source": [
    "### Pre-processing sulle trame\n",
    "\n",
    "Attraverso le funzioni messe a disposizione dalla libreria \"SpaCy\", effettuiamo un lavoro di pre-procesing sulle trame dei libri. <br>\n",
    "\n",
    "Per quanto riguarda la rimozione delle Stop Words, all'interno di SpaCy è già implementato un vocabolario che contiene le possibili Stop Words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7822e6a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'made', 'fifty', \"'re\", 'forty', 'seems', 'who', 'into', 'call', 'everywhere', 'elsewhere', 'eight', 'yourselves', 'mostly', 'whether', 'also', 'has', 'several', 'further', 'ever', 'beyond', 'although', 'due', 'themselves', 'as', 'your', 'why', 'being', 'hundred', 'no', 'over', 'and', 'did', 'n‘t', 'more', 'must', 'nowhere', 'again', 'becoming', '‘ve', 'since', '‘m', 'in', 'latter', 'nobody', 'former', 'have', 'meanwhile', 'how', 'hereupon', 'get', 'such', 'nevertheless', 'both', 'much', 'n’t', 'hereafter', 'hereby', 'side', 'per', 'others', 'towards', 'next', 'thru', 'here', 'wherein', 'nor', 'unless', 'ten', 'less', 'really', 'namely', 'either', 'throughout', 'they', 'be', 'two', 'put', 'ourselves', 'whenever', 'it', 'after', 'thereupon', 'noone', 'those', \"n't\", 'everything', 'each', 'full', 'on', 'under', 'doing', 'yours', 'becomes', 'else', 'somewhere', \"'ll\", 'which', 'with', 'if', 'out', 'last', 'now', 'nine', 'sometimes', 'our', 'thereafter', 'three', 'anyone', 'he', 'therein', 'rather', 'five', 'together', 'beside', 'part', 'toward', 'anyway', 'hence', 'against', 'across', 'except', 'their', 'his', 'my', 'thence', 'somehow', 'not', 'most', 'anyhow', 'mine', '‘d', 'seeming', 'quite', 'will', 'still', '’s', 'what', 'own', 'whither', 'the', 'say', 'do', 'go', 'third', 'other', 'ours', 'himself', 'by', 'latterly', 'below', 'whereby', 'serious', 'had', 'give', 'four', 'than', 'at', 'moreover', 'are', 'anything', 'beforehand', 'back', 'hers', 'besides', 'various', '’re', 'few', 'only', 'many', 'make', 'via', 'seemed', 'off', 'first', 'eleven', 'herein', 'you', 'using', 'cannot', 'its', 'show', 'was', 'alone', 'from', 'an', '’m', 'though', 'please', 'yourself', 'another', 'onto', 'perhaps', '’ve', 'can', 'does', '’ll', 'through', 'nothing', 'within', 'however', 'too', 'seem', 'she', 'used', 'i', 'bottom', 'may', 'were', 'while', 'something', 'see', 'any', \"'ve\", 'should', 'often', 'same', 'everyone', 'never', \"'s\", 'but', 'to', 'whereas', 'upon', 'anywhere', 'would', 'just', 'least', 'therefore', 'them', 'when', 'afterwards', '‘ll', 'thereby', 'me', 'whence', 'indeed', 'before', 'could', 'of', 'around', 'whoever', 'herself', 'am', 'fifteen', '‘s', 'been', 'all', 'us', '’d', 'until', 're', 'twelve', 'we', 'formerly', 'whereupon', 'a', 'itself', 'keep', 'during', 'whose', 'about', 'sixty', 'very', 'became', 'or', '‘re', 'her', 'even', 'twenty', 'almost', 'take', 'for', 'whereafter', 'someone', 'once', 'well', 'that', 'name', 'this', 'always', 'down', 'along', 'six', 'some', 'among', 'front', 'whatever', 'otherwise', 'empty', 'whole', 'there', 'without', 'become', 'him', 'wherever', 'so', 'neither', \"'m\", 'then', 'above', 'is', 'up', 'already', 'move', 'enough', 'because', 'myself', 'amount', 'between', 'one', 'where', 'might', 'none', 'yet', 'ca', 'whom', 'every', 'thus', 'sometime', 'these', 'top', 'done', \"'d\", 'amongst', 'regarding', 'behind'}\n"
     ]
    }
   ],
   "source": [
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a89b33",
   "metadata": {},
   "source": [
    "### Calcolo della rappresentazione \"Word Embedding\" delle trame\n",
    "\n",
    "Come già detto, il calcolo della rappresentazione word embedding di un intero documento prevede dei passi ben precisi:\n",
    "\n",
    "- estrazione delle parole dal testo\n",
    "- calcolo della rappresentazione Word Embedding delle singole parole\n",
    "- calcolo della rappresentazione Word Embedding dell'intero documento come media delle rappresentazioni delle parole in esso contenute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be66188c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [04:33<00:00,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "plotEmbeddings = []\n",
    "\n",
    "for i in tqdm(range (len(booksSample))):\n",
    "    plot = nlp(booksSample.iloc[i]['Summary'])\n",
    "    # Tokenizzazione, rimozione delle stop word e lemmatizzazione\n",
    "    tokens = [token.lemma_ for token in plot if not token.is_stop and not token.is_punct]\n",
    "    wordEmbeddings = []\n",
    "    for t in tokens:\n",
    "        wordEmbeddings.append(nlp(t).vector)\n",
    "    emb = np.mean(wordEmbeddings,0)\n",
    "    plotEmbeddings.append(emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3713eef",
   "metadata": {},
   "source": [
    "Adesso, così come fatto nel caso di Bag of Words, possiamo calcolare le similarità tra la rappresentazione delle keyword fornite in input dall'utente e le rappresentazioni delle trame dei singoli libri.<br>\n",
    "Anche in questo caso, usiamo come misura di similarità la **similarità del coseno**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38fb5526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libri più simili alle parole chiave date in input:\n",
      "\n",
      "Animal Farm  ,  George Orwell (coeff. similarità:  0.89561796 )\n",
      "Ishmael  ,  Daniel Quinn (coeff. similarità:  0.8559113 )\n",
      "The Memory of Earth  ,  Orson Scott Card (coeff. similarità:  0.8425473 )\n"
     ]
    }
   ],
   "source": [
    "keywords = \"story of a group of farm animals who rebel against their human farmer, hoping to create a society where the animals can be equal, free, and happy. Ultimately, the rebellion is betrayed, and under the dictatorship of a pig named Napoleon, the farm ends up in a state as bad as it was before\"\n",
    "\n",
    "keywords = nlp(keywords)\n",
    "tokens = [token.lemma_ for token in keywords if not token.is_stop and not token.is_punct]\n",
    "wordEmbeddings = []\n",
    "for t in tokens:\n",
    "    wordEmbeddings.append(nlp(t).vector)\n",
    "keywords = np.mean(wordEmbeddings,0)\n",
    "\n",
    "similarities = []\n",
    "\n",
    "for i in range(len(booksSample)):\n",
    "    similarities.append((booksSample.iloc[i]['Title'] , booksSample.iloc[i]['Author'] ,dot(keywords, plotEmbeddings[i])/(norm(keywords)*norm(plotEmbeddings[i]))))\n",
    "\n",
    "sortedSimilarities = sorted(similarities, key=lambda similarities: similarities[2] , reverse=True)\n",
    "\n",
    "print(\"Libri più simili alle parole chiave date in input:\\n\")\n",
    "for i in range(3):\n",
    "    print(sortedSimilarities[i][0] , \" , \", sortedSimilarities[i][1] , \"(coeff. similarità: \" , sortedSimilarities[i][2], \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ed1776",
   "metadata": {},
   "source": [
    "# Valutazione dei risultati\n",
    "\n",
    "Al fine di valutare le performance del sistema, usiamo il cosiddetto \"***Mean Reciprocal Rank***\". <br><br>\n",
    "Il Mean Reciprocal Rank (MRR) è un indice statistico che permette di valutare un algoritmo che produce una lista di possibili risposte ad una query, le quali sono ordinate per \"probabilità di correttezza\".<br> In questo caso, una query equivale alla ricerca di libri simili a delle parole chiave, mentre la probabilità di correttezza è data dal coefficente di similarità tra le rappresentazioni delle keyword inserite in input e le trame dei libri.\n",
    "\n",
    "Formalmente, il Mean Reciprocal Rank è definito come:\n",
    "$$MRR=\\frac{1}{\\left | Q \\right |}\\cdot \\sum_{i=1}^{\\left | Q \\right |} \\frac{1}{rank_{i}}$$\n",
    "dove Q è l'insieme delle query, mentre $$rank_i$$ è la \"posizione\" del \"risultato atteso\" dalla query *i*-esima nella lista dei risultati restituita dall'algoritmo, ordinata secondo le probabilità di correttezza.\n",
    "<br><br>\n",
    "Per effettuare il processo di valutazione, eseguiamo le seguenti operazioni:\n",
    "\n",
    "- definiamo un insieme di 20 libri, rispetto ai quali scegliamo un insieme di parole chiave che li descrivono: avremo quindi 20 query\n",
    "- eseguiamo l'algoritmo usando ogni volta uno degli insiemi di parole chiave definiti al passo precedente, e calcoliamo per ognuno dei libri il rispettivo \"Rank\", cioè la \"posizione\" di tale libro nella lista dei risultati restituiti dall'algoritmo\n",
    "- calcoliamo il MRR dell'algoritmo\n",
    "\n",
    "***N.B.*** *per una valutazione dei risultati più coerente, consideriamo anche per Bag of Words la stessa frazione del dataset usata nel caso di Word Embeddings.*\n",
    "\n",
    "### Definizione dell'insieme dei libri utili ad effettuare la valutazione\n",
    "\n",
    "Consideriamo i primi 20 libri del dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb350fda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia ID</th>\n",
       "      <th>Freebase ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Pub date</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>620</td>\n",
       "      <td>/m/0hhy</td>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>1945-08-17</td>\n",
       "      <td>Roman à clef,Satire,Children's literature,Spec...</td>\n",
       "      <td>Old Major, the old boar on the Manor Farm, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>843</td>\n",
       "      <td>/m/0k36</td>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>Anthony Burgess</td>\n",
       "      <td>1962</td>\n",
       "      <td>Science Fiction,Novella,Speculative fiction,Ut...</td>\n",
       "      <td>Alex, a teenager living in near-future Englan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>986</td>\n",
       "      <td>/m/0ldx</td>\n",
       "      <td>The Plague</td>\n",
       "      <td>Albert Camus</td>\n",
       "      <td>1947</td>\n",
       "      <td>Existentialism,Fiction,Absurdist fiction,Novel</td>\n",
       "      <td>The text of The Plague is divided into five p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2080</td>\n",
       "      <td>/m/0wkt</td>\n",
       "      <td>A Fire Upon the Deep</td>\n",
       "      <td>Vernor Vinge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hard science fiction,Science Fiction,Speculati...</td>\n",
       "      <td>The novel posits that space around the Milky ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2152</td>\n",
       "      <td>/m/0x5g</td>\n",
       "      <td>All Quiet on the Western Front</td>\n",
       "      <td>Erich Maria Remarque</td>\n",
       "      <td>1929-01-29</td>\n",
       "      <td>War novel,Roman à clef</td>\n",
       "      <td>The book tells the story of Paul Bäumer, a Ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2890</td>\n",
       "      <td>/m/011zx</td>\n",
       "      <td>A Wizard of Earthsea</td>\n",
       "      <td>Ursula K. Le Guin</td>\n",
       "      <td>1968</td>\n",
       "      <td>Children's literature,Fantasy,Speculative fict...</td>\n",
       "      <td>Ged is a young boy on Gont, one of the larger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4081</td>\n",
       "      <td>/m/01b4w</td>\n",
       "      <td>Blade Runner 3: Replicant Night</td>\n",
       "      <td>K. W. Jeter</td>\n",
       "      <td>1996-10-01</td>\n",
       "      <td>Science Fiction,Speculative fiction</td>\n",
       "      <td>Living on Mars, Deckard is acting as a consul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4082</td>\n",
       "      <td>/m/01b56</td>\n",
       "      <td>Blade Runner 2: The Edge of Human</td>\n",
       "      <td>K. W. Jeter</td>\n",
       "      <td>1995-10-01</td>\n",
       "      <td>Science Fiction,Speculative fiction</td>\n",
       "      <td>Beginning several months after the events in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6020</td>\n",
       "      <td>/m/01t5z</td>\n",
       "      <td>Crash</td>\n",
       "      <td>J. G. Ballard</td>\n",
       "      <td>1973</td>\n",
       "      <td>Speculative fiction,Fiction,Novel</td>\n",
       "      <td>The story is told through the eyes of narrato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6628</td>\n",
       "      <td>/m/01y92</td>\n",
       "      <td>Children of Dune</td>\n",
       "      <td>Frank Herbert</td>\n",
       "      <td>1976</td>\n",
       "      <td>Science Fiction,Speculative fiction,Children's...</td>\n",
       "      <td>Nine years after Emperor Paul Muad'dib walked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6629</td>\n",
       "      <td>/m/01y9j</td>\n",
       "      <td>Candide, ou l'Optimisme</td>\n",
       "      <td>Voltaire</td>\n",
       "      <td>1759-01</td>\n",
       "      <td>Satire,Bildungsroman,Picaresque novel</td>\n",
       "      <td>Candide contains thirty episodic chapters, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6630</td>\n",
       "      <td>/m/01yb0</td>\n",
       "      <td>Chapterhouse Dune</td>\n",
       "      <td>Frank Herbert</td>\n",
       "      <td>1985-04</td>\n",
       "      <td>Science Fiction,Speculative fiction,Children's...</td>\n",
       "      <td>The situation is desperate for the Bene Gesse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6921</td>\n",
       "      <td>/m/01_mr</td>\n",
       "      <td>Carmilla</td>\n",
       "      <td>Sheridan Le Fanu</td>\n",
       "      <td>1872</td>\n",
       "      <td>Gothic fiction</td>\n",
       "      <td>The story is presented by Le Fanu as part of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7817</td>\n",
       "      <td>/m/025zx</td>\n",
       "      <td>The Cider House Rules</td>\n",
       "      <td>John Irving</td>\n",
       "      <td>1985</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Homer Wells grows up in an orphanage where he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7923</td>\n",
       "      <td>/m/026l0</td>\n",
       "      <td>Dracula</td>\n",
       "      <td>Bram Stoker</td>\n",
       "      <td>1897</td>\n",
       "      <td>Science Fiction,Speculative fiction,Horror,Inv...</td>\n",
       "      <td>The novel is told in epistolary format, as a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8237</td>\n",
       "      <td>/m/0297f</td>\n",
       "      <td>Don Quixote</td>\n",
       "      <td>Miguel de Cervantes</td>\n",
       "      <td>1605</td>\n",
       "      <td>Parody,Children's literature,Psychological nov...</td>\n",
       "      <td>The First Sally Alonso Quijano, the protagoni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8567</td>\n",
       "      <td>/m/02cxx</td>\n",
       "      <td>Dune Messiah</td>\n",
       "      <td>Frank Herbert</td>\n",
       "      <td>1969</td>\n",
       "      <td>Science Fiction,Speculative fiction,Children's...</td>\n",
       "      <td>Twelve years after the events described in Du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8757</td>\n",
       "      <td>/m/02fck</td>\n",
       "      <td>Darwin's Dangerous Idea</td>\n",
       "      <td>Daniel Dennett</td>\n",
       "      <td>1995</td>\n",
       "      <td>Philosophy,Science</td>\n",
       "      <td>\"Starting in the Middle\", Part I of Darwin's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9000</td>\n",
       "      <td>/m/02h3j</td>\n",
       "      <td>Death of a Hero</td>\n",
       "      <td>Richard Aldington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Death of a Hero is the story of a young Engli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10861</td>\n",
       "      <td>/m/02y0f</td>\n",
       "      <td>The Trial</td>\n",
       "      <td>Franz Kafka</td>\n",
       "      <td>1925</td>\n",
       "      <td>Fiction,Absurdist fiction,Novel</td>\n",
       "      <td>On his thirtieth birthday, the chief financia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Wikipedia ID Freebase ID                              Title  \\\n",
       "0            620     /m/0hhy                        Animal Farm   \n",
       "1            843     /m/0k36                 A Clockwork Orange   \n",
       "2            986     /m/0ldx                         The Plague   \n",
       "3           2080     /m/0wkt               A Fire Upon the Deep   \n",
       "4           2152     /m/0x5g     All Quiet on the Western Front   \n",
       "5           2890    /m/011zx               A Wizard of Earthsea   \n",
       "6           4081    /m/01b4w    Blade Runner 3: Replicant Night   \n",
       "7           4082    /m/01b56  Blade Runner 2: The Edge of Human   \n",
       "8           6020    /m/01t5z                              Crash   \n",
       "9           6628    /m/01y92                   Children of Dune   \n",
       "10          6629    /m/01y9j            Candide, ou l'Optimisme   \n",
       "11          6630    /m/01yb0                  Chapterhouse Dune   \n",
       "12          6921    /m/01_mr                           Carmilla   \n",
       "13          7817    /m/025zx              The Cider House Rules   \n",
       "14          7923    /m/026l0                            Dracula   \n",
       "15          8237    /m/0297f                        Don Quixote   \n",
       "16          8567    /m/02cxx                       Dune Messiah   \n",
       "17          8757    /m/02fck            Darwin's Dangerous Idea   \n",
       "18          9000    /m/02h3j                    Death of a Hero   \n",
       "19         10861    /m/02y0f                          The Trial   \n",
       "\n",
       "                  Author    Pub date  \\\n",
       "0          George Orwell  1945-08-17   \n",
       "1        Anthony Burgess        1962   \n",
       "2           Albert Camus        1947   \n",
       "3           Vernor Vinge         NaN   \n",
       "4   Erich Maria Remarque  1929-01-29   \n",
       "5      Ursula K. Le Guin        1968   \n",
       "6            K. W. Jeter  1996-10-01   \n",
       "7            K. W. Jeter  1995-10-01   \n",
       "8          J. G. Ballard        1973   \n",
       "9          Frank Herbert        1976   \n",
       "10              Voltaire     1759-01   \n",
       "11         Frank Herbert     1985-04   \n",
       "12      Sheridan Le Fanu        1872   \n",
       "13           John Irving        1985   \n",
       "14           Bram Stoker        1897   \n",
       "15   Miguel de Cervantes        1605   \n",
       "16         Frank Herbert        1969   \n",
       "17        Daniel Dennett        1995   \n",
       "18     Richard Aldington         NaN   \n",
       "19           Franz Kafka        1925   \n",
       "\n",
       "                                               Genres  \\\n",
       "0   Roman à clef,Satire,Children's literature,Spec...   \n",
       "1   Science Fiction,Novella,Speculative fiction,Ut...   \n",
       "2      Existentialism,Fiction,Absurdist fiction,Novel   \n",
       "3   Hard science fiction,Science Fiction,Speculati...   \n",
       "4                              War novel,Roman à clef   \n",
       "5   Children's literature,Fantasy,Speculative fict...   \n",
       "6                 Science Fiction,Speculative fiction   \n",
       "7                 Science Fiction,Speculative fiction   \n",
       "8                   Speculative fiction,Fiction,Novel   \n",
       "9   Science Fiction,Speculative fiction,Children's...   \n",
       "10              Satire,Bildungsroman,Picaresque novel   \n",
       "11  Science Fiction,Speculative fiction,Children's...   \n",
       "12                                     Gothic fiction   \n",
       "13                                            Fiction   \n",
       "14  Science Fiction,Speculative fiction,Horror,Inv...   \n",
       "15  Parody,Children's literature,Psychological nov...   \n",
       "16  Science Fiction,Speculative fiction,Children's...   \n",
       "17                                 Philosophy,Science   \n",
       "18                                            Fiction   \n",
       "19                    Fiction,Absurdist fiction,Novel   \n",
       "\n",
       "                                              Summary  \n",
       "0    Old Major, the old boar on the Manor Farm, ca...  \n",
       "1    Alex, a teenager living in near-future Englan...  \n",
       "2    The text of The Plague is divided into five p...  \n",
       "3    The novel posits that space around the Milky ...  \n",
       "4    The book tells the story of Paul Bäumer, a Ge...  \n",
       "5    Ged is a young boy on Gont, one of the larger...  \n",
       "6    Living on Mars, Deckard is acting as a consul...  \n",
       "7    Beginning several months after the events in ...  \n",
       "8    The story is told through the eyes of narrato...  \n",
       "9    Nine years after Emperor Paul Muad'dib walked...  \n",
       "10   Candide contains thirty episodic chapters, wh...  \n",
       "11   The situation is desperate for the Bene Gesse...  \n",
       "12   The story is presented by Le Fanu as part of ...  \n",
       "13   Homer Wells grows up in an orphanage where he...  \n",
       "14   The novel is told in epistolary format, as a ...  \n",
       "15   The First Sally Alonso Quijano, the protagoni...  \n",
       "16   Twelve years after the events described in Du...  \n",
       "17   \"Starting in the Middle\", Part I of Darwin's ...  \n",
       "18   Death of a Hero is the story of a young Engli...  \n",
       "19   On his thirtieth birthday, the chief financia...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = books.head(n=20)\n",
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c71d50",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<br><br><br><br><br><br><br>\n",
    "### Definizione delle parole chiave per ognuno di essi\n",
    "\n",
    "Definiamo per ognuno dei libri scelti un insieme di frasi che ne descrive la trama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b727bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryHardCoded = []\n",
    "\n",
    "summaryHardCoded.append(\"story of a group of farm animals who rebel against their human farmer, hoping to create a society where the animals can be equal, free, and happy. Ultimately, the rebellion is betrayed, and under the dictatorship of a pig, the farm ends up in a state as bad as it was before\")\n",
    "summaryHardCoded.append(\"In search of strong emotions, a boy commits many criminal acts. He is arrested and subjected to a treatment that conditions him to non-violence. Released from prison, all the people who have suffered violence from him turn against him\")\n",
    "summaryHardCoded.append(\"Story about rats and a plague that breaks out. At first, everyone is in denial. But after a lockdown is imposed, people decide to fight the disease by organizing volunteers in sanitary squads. At the end, the plague is defeated, families and lovers are reunited and life begins anew\")\n",
    "summaryHardCoded.append(\"story in an universe whit different physical laws. The galaxy is not unique: it is divided into different zones. In zones an advanced civilizations live. the galaxy is threatened by an unknown entity that wants to destroy it \")\n",
    "summaryHardCoded.append(\"story during the World War I, when a young German soldier, after enlisting in the German Army with his friends, he finds himself exposed to the realities of war, shattering his early hopes of becoming a hero as he does his best to survive.\")\n",
    "summaryHardCoded.append(\"Story of a young mage who lives in an island. He is very powerful and learn magic at school, but he runs into conflict with other students.\")\n",
    "summaryHardCoded.append(\"Living on Mars, a man called Deckard is acting as a consultant to a movie crew filming the story of his days as a blade runner. He finds himself drawn into a mission on behalf of the 'replicants' he was once assigned to kill. Meanwhile, the mystery surrounding the beginnings of the Tyrell Corporation is being exposed.\")\n",
    "summaryHardCoded.append(\"The main character, Decard, refuges into an house with a woman, but soon a man visit them in order to ask to find a lost 'recplicant'. \")\n",
    "summaryHardCoded.append(\"story about car-crash sexual fetishism: its protagonists become sexually aroused by staging and participating in real car crashes, inspired by the famous crashes of celebrities.\")\n",
    "summaryHardCoded.append(\"A man arrived in the desert. With his children still being infants, the emperor’s throne becomes a vacant position.\")\n",
    "summaryHardCoded.append(\"The protagonist was born in the castle of a Baron in Westphalia. He is educated by an 'optimistic' philosopher, a convinced assertor that 'everything goes in the best possible way' in the world. He fell in love with the daughter of Baron, so he is driven out of the castle and begins to accumulate experiences, undergoes many hardships which do not seem to confirm Pangloss's optimism. He travel around the world and he enlisted by force, where he miraculously escapes death. Then he learns that the castle has been sacked, so he return and frees the baron and his daughter. At the end, he remains with her in a farm on the banks of the Bosphorus, works the land and thinks about the meaning of the experiences he lived.\")\n",
    "summaryHardCoded.append(\"story about struggles of the Bene Gesserit Sisterhood against the violent Honored Matres, who are succeeding in their bid to seize control of the universe and destroy the factions and planets that oppose them\")\n",
    "summaryHardCoded.append(\"In an isolated castle deep in the Styrian forest, Laura leads a solitary life with only her elderly father for company. Until one moonlit night, a horse-drawn carriage crashes into view, carrying an unexpected guest.So begins a feverish friendship between Laura and her mysterious, entrancing companion. But as Carmilla becomes increasingly strange and volatile, prone to eerie nocturnal wanderings, Laura finds herself tormented by nightmares and growing weaker by the day\")\n",
    "summaryHardCoded.append(\"A young orphan grows up in an orphanage run by a pro-abortion doctor.The orphanage is a place that welcomes children and women in need both to give birth and to abort unwanted children. Here he grows up and, after unsuccessful adoption experiences, decides to stay in the orphanage to help the doctor, but as he grows up he decides to totally change his life and leave the place where he grew up.\")\n",
    "summaryHardCoded.append(\"A man about to get married goes to Transylvania to conclude the sale of a house in London to a earl: here he discovers that the earl is actually a vampire.The earl traps the man in his castle and then leaves for England. At this point the vampire begins to kill people, until a professor together with the man who had been trapped manage to kill the vampire.\")\n",
    "summaryHardCoded.append(\"Story of the life and insightful journey of a Spanish man who seems to be losing his mind on his quest to become a knight and restore chivalry alongside, with whom he fights multiple imaginary enemies and faces a series of fantastic challenges.\")\n",
    "summaryHardCoded.append(\"After the death of Baron Harkonnen and the defeat of the Sardaukar troops, Paul Atreides, heir of House Atreides, assumes the throne as the emperor of the known universe with Princess Irulan as his consort and his Fremen lover, Chani as his concubine. Twelve years later, Paul Atreides holds total control over the supply of Melange; this gives him immense power over the entire universe. With the Fremen using his name as a messiah figure, a brutal jihad gets unleashed on humanity, killing billions of people.\")\n",
    "summaryHardCoded.append(\"Book which analyze the Charles Darwin theory about the evolution and in particular aboute the 'natural selection'\")\n",
    "summaryHardCoded.append(\"When word comes that the protagonist was killed in the war, his friend tries to reconstruct the life of the dead man to see what forces caused his death. The friend served with George at various times during the war, and it is his belief that George deliberately exposed himself to German fire because he no longer wanted to live.\")\n",
    "summaryHardCoded.append(\"Story of a young man who finds himself caught up in the mindless bureaucracy of the law has become synonymous with the anxieties and sense of alienation of the modern age and with an ordinary person’s struggle against an unreasoning and unreasonable authority\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d811f91",
   "metadata": {},
   "source": [
    "Calcoliamo adesso il MRR dell'algoritmo, considerando prima i testi rappresentati con Bag of Words, e successivamente con Word Embeddings.\n",
    "\n",
    "### MRR con rappresentazione Bag of Words\n",
    "\n",
    "Prima di tutto, è necessario calcolare la rappresentazione Bag of Words delle \"query\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "004a8996",
   "metadata": {},
   "outputs": [],
   "source": [
    "queryBOW = []\n",
    "\n",
    "for i in range(20):\n",
    "    queryBOW.append(np.array(count_vect.transform([summaryHardCoded[i]]).todense()).flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80490519",
   "metadata": {},
   "source": [
    "Calcoliamo adesso l'MRR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13ea583b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 11.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR con Bag of Words =  0.4186654306963017 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "totRank = 0.0\n",
    "\n",
    "for i in tqdm(range(20)):   # fisso la query\n",
    "    similarities = []\n",
    "    for j in range(len(booksSample)):   # scorro tutti i 200 libri del dataset\n",
    "        title = booksSample.iloc[j][\"Title\"]\n",
    "        similarities.append( tuple ((title , (dot(BOWSummaries[j], queryBOW[i]))/(norm(BOWSummaries[j])*norm(queryBOW[i])))  )  )\n",
    "    \n",
    "    sortedSimilarities = sorted(similarities, key=lambda similarities: similarities[1] , reverse=True) #ordino per similarità\n",
    "    \n",
    "    rank = 1\n",
    "    for j in range(len(sortedSimilarities)):\n",
    "        if sortedSimilarities[j][0] != booksSample.iloc[i][\"Title\"]:\n",
    "            rank = rank + 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    totRank = totRank + (1/rank)\n",
    "    \n",
    "MRR = totRank / 20\n",
    "\n",
    "print(\"MRR con Bag of Words = \",MRR,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8058381",
   "metadata": {},
   "source": [
    "### MRR con rappresentazione Word Embeddings\n",
    "\n",
    "Effettuiamo adesso lo stesso procedimento utilizzando la rappresentazione Word Emeddings.\n",
    "Calcoliamo prima di tutto la rappresentazione Word Embeddings di tutte le query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34d07131",
   "metadata": {},
   "outputs": [],
   "source": [
    "queryEMB = []\n",
    "\n",
    "for i in range(20):\n",
    "    tokens = [token.lemma_ for token in nlp(summaryHardCoded[i]) if not token.is_stop and not token.is_punct]\n",
    "    wordEmbeddings = []\n",
    "    for t in tokens:\n",
    "        wordEmbeddings.append(nlp(t).vector)\n",
    "    queryEMB.append(np.mean(wordEmbeddings,0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6f96be",
   "metadata": {},
   "source": [
    "Infine, calcoliamo il MRR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "729b3f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 46.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR con Word Embeddings =  0.5143330912308823 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "totRank = 0.0\n",
    "\n",
    "for i in tqdm(range(20)):   # fisso la query\n",
    "    similarities = []\n",
    "    for j in range(len(booksSample)):   # scorro gli embedding dei libri\n",
    "        title = booksSample.iloc[j][\"Title\"]\n",
    "        similarities.append( tuple ((title , (dot(plotEmbeddings[j], queryEMB[i]))/(norm(plotEmbeddings[j])*norm(queryEMB[i])))  )  )\n",
    "    \n",
    "    sortedSimilarities = sorted(similarities, key=lambda similarities: similarities[1] , reverse=True) #ordino per similarità\n",
    "    \n",
    "    rank = 1\n",
    "    for j in range(len(sortedSimilarities)):\n",
    "        if sortedSimilarities[j][0] != booksSample.iloc[i][\"Title\"]:\n",
    "            rank = rank + 1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    totRank = totRank + (1/rank)\n",
    "           \n",
    "MRR = totRank / 20\n",
    "\n",
    "print(\"MRR con Word Embeddings = \",MRR,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2782bc3e",
   "metadata": {},
   "source": [
    "# Conclusioni\n",
    "\n",
    "Dai risultati e dalle misurazioni delle performance dell'algoritmo basate sulla misura \"MRR\", possiamo concludere che **le performance del sistema sono superiori se i testi sono rappresentati attraverso la rappresentazione Word Embeddings**.<br>\n",
    "\n",
    "Ciò intuitivamente può essere dovuto alle proprietà di tale rappresentazione, la quale, come già detto, tiene conto non solo della presenza di specifici termini nel testo da analizzare, ma anche e soprattutto del **modo con cui tali termini sono utilizzati nel testo**, dando quindi la possibilità di effettuare delle raccomandazioni più precise rispetto a quanto è possibile fare utilizzando invece la rappresentazione Bag of Words.\n",
    "\n",
    "<br>\n",
    "Bisogna inoltre considerare che l'analisi delle performance è effettuata soltanto su una porzione ridotta del dataset: con molta probabilità, effettuando tali analisi rispetto all'intero dataset e con un maggior numero di query, la differenza di performance tra le due varianti dell'algoritmo diventerebbe ancora più marcata."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
